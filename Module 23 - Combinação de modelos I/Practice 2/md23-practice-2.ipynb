{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb6a816-ff6f-403b-8622-0ca33cea960b",
   "metadata": {},
   "source": [
    "# Tarefa 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413cb77c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01af968-8131-4047-936f-ee55315b09a4",
   "metadata": {},
   "source": [
    "**1.** Monte um passo a passo para o algoritmo RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527cc51a-cdf8-44ae-b8d8-93ebce1009e1",
   "metadata": {},
   "source": [
    "Similar ao Bagging, o Random Forest segue os seguintes passos:\n",
    "\n",
    "1. Bootstrap + Seleção de Características: Da mesma forma que o Bagging, o Random Forest utiliza amostras aleatórias com reposição do conjunto de dados original. Contudo, em cada uma dessas amostras, apenas um subconjunto aleatório de variáveis é selecionado (feature selection). Para problemas de classificação, é comum escolher a raiz quadrada do número total de variáveis, enquanto em problemas de regressão, é usual selecionar um terço das variáveis.\n",
    "\n",
    "2. Modelagem com Árvores de Decisão: Nesta etapa, um modelo de Machine Learning, especificamente uma árvore de decisão, é treinado de forma independente em cada amostra bootstrap, utilizando as variáveis aleatórias definidas no passo anterior.\n",
    "\n",
    "3. Agregação: Por fim, os resultados de cada modelo independente (cada árvore de decisão) são agregados para obter uma previsão final. Em problemas de classificação, a agregação geralmente é realizada por meio do voto majoritário, onde a classe mais prevista pelos modelos individuais é escolhida como a classe final. Em problemas de regressão, a agregação é feita calculando a média das previsões dos modelos individuais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805122b5-5f98-4013-bac2-d36ed341325c",
   "metadata": {},
   "source": [
    "**2.** Explique com suas palavras o Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7b205-08c5-45a8-a29e-45e1c9baf2b5",
   "metadata": {},
   "source": [
    "O Random Forest pode ser conceituado como uma ampliação do Bootstrap Aggregating, também conhecido como Bagging, oferecendo melhorias em desempenho e resultados. Assim como no Bagging, o Random Forest é um método de combinação de modelos de Machine Learning, onde cada modelo é treinado em variações do conjunto de dados original. Essas variações, denominadas amostras bootstrap, consistem em subconjuntos aleatórios do conjunto de dados original, com possíveis repetições, mantendo o mesmo número de observações. No entanto, o Random Forest se diferencia ao utilizar apenas uma quantidade determinada e aleatória de variáveis em cada modelo, especialmente em modelos de árvore de decisão. Esta abordagem tem como objetivo reduzir a variância dos resultados e mitigar o risco de overfitting. Para obter a previsão final, a agregação dos modelos é realizada de forma semelhante ao Bagging, onde a média é empregada para regressão e votação para classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a54f311-a631-4d9c-a2e0-92064484db82",
   "metadata": {},
   "source": [
    "**3.** Qual a diferença entre Bagging e Random Forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd86441-282d-434f-8a6c-c84f668a7a31",
   "metadata": {},
   "source": [
    "\n",
    "A distinção entre Bagging e Random Forest reside no desempenho e na redução da variância entre os resultados dos modelos. Bagging é uma técnica mais ampla de combinação de modelos de Machine Learning que utiliza amostragem aleatória, enquanto Random Forest é uma variação mais específica desse método que emprega árvores de decisão. No Random Forest, cada modelo é treinado em subconjuntos aleatórios do conjunto de dados original, com uma quantidade reduzida e aleatória de variáveis consideradas em cada modelo. Essa abordagem aumenta a robustez do modelo e, ao combinar os resultados dos modelos, a previsão final tende a ser mais precisa do que no Bagging. Portanto, Random Forest é uma extensão aprimorada do Bagging, oferecendo um desempenho superior e uma redução adicional na variância dos resultados.\n",
    "\n",
    "**Em resumo, ``Random Forest`` funciona melhor que o Bagging, pois as árvores amostradas são mais independentes (menor correlação).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4478db89-7ae8-4216-a600-9f5c97f3cbf0",
   "metadata": {},
   "source": [
    "**4.** (Opcional) Implementar em python o Random Forest\n",
    "> - Bootstrap\n",
    "> - Feature selection\n",
    "> - Modelagem com Decision trees\n",
    "> - Agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a698d4e7-cef9-411a-9227-f6a0ce9e5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import das bibliotecas:\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets        import load_iris\n",
    "from sklearn.datasets        import load_diabetes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.metrics         import accuracy_score\n",
    "\n",
    "from sklearn.tree            import DecisionTreeRegressor\n",
    "from sklearn.metrics         import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9eebb7d-9eda-475d-87f6-a8565dd80612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "Accuracy score: 0.94\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_test  y_pred\n",
       "0        2       2\n",
       "1        0       0\n",
       "2        0       0\n",
       "3        1       1\n",
       "4        0       0\n",
       "5        0       0\n",
       "6        2       2\n",
       "7        0       0\n",
       "8        2       2\n",
       "9        0       0\n",
       "10       2       2\n",
       "11       2       2\n",
       "12       1       1\n",
       "13       0       0\n",
       "14       2       2\n",
       "15       2       2\n",
       "16       1       1\n",
       "17       1       1\n",
       "18       1       1\n",
       "19       1       1\n",
       "20       1       1\n",
       "21       2       2\n",
       "22       2       2\n",
       "23       1       2\n",
       "24       2       2\n",
       "25       2       2\n",
       "26       2       2\n",
       "27       1       1\n",
       "28       1       1\n",
       "29       1       1\n",
       "30       0       0\n",
       "31       2       2\n",
       "32       2       2\n",
       "33       2       2\n",
       "34       1       2\n",
       "35       2       2\n",
       "36       1       1\n",
       "37       2       1\n",
       "38       1       1\n",
       "39       0       0\n",
       "40       2       2\n",
       "41       0       0\n",
       "42       0       0\n",
       "43       1       1\n",
       "44       0       0\n",
       "45       2       2\n",
       "46       0       0\n",
       "47       2       2\n",
       "48       1       1\n",
       "49       2       2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo da técnica Random Forest para problemas de classificação:\n",
    "\n",
    "X = load_iris().data\n",
    "y = load_iris().target\n",
    "\n",
    "df = pd.DataFrame(X, columns=load_iris().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_classifier(df:pd.DataFrame, \n",
    "                  num_bootstrap_samples:int=3,  # Parâmetro da função que define a quantidade de amostragens para treinamento\n",
    "                  test_size:float=0.25\n",
    "                 ) -> pd.DataFrame:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "    X_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "    \n",
    "    # Dicionário para os resultados das predições de cada modelo\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        # Bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train), \n",
    "                                   replace=True)  # Amostragem COM reposição\n",
    "\n",
    "        X_train = df_train.drop(['target'], axis=1)\n",
    "        # Feature selection\n",
    "        X_train = X_train.sample(n=round(np.sqrt(X_train.shape[1])),  # Cálculo da raiz quadrada da quantidade de variáveis\n",
    "                                 axis=1)\n",
    "        \n",
    "        y_train = df_train['target']\n",
    "        \n",
    "        # Modelagem (base learners)\n",
    "        model = DecisionTreeClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Adicionando os resultados do modelo ao dicionário para agregação das predições\n",
    "        y_pred_bagging.update({i:model.predict(X_test[X_train.columns])})\n",
    "    \n",
    "    # Aggregating\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "                .mode(axis=1)  # Agregando o valor com maior número de aparições nas predições dos modelos\n",
    "                .rename(columns={0:'y_pred'}))\n",
    " \n",
    "    # Resultados\n",
    "    print(model)\n",
    "    print('Accuracy score:', accuracy_score(y_true=y_test, \n",
    "                                            y_pred=y_pred['y_pred']\n",
    "                                           ))\n",
    "\n",
    "    return pd.concat(objs=[y_test.reset_index(drop=True), \n",
    "                           y_pred['y_pred'].astype(int)], \n",
    "                     axis=1)\n",
    "\n",
    "rf_classifier(num_bootstrap_samples=10, df=df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c44692d5-b1a0-4351-af50-6941709045c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor()\n",
      "Mean squared error: 4499.433081769329\n",
      "Coefficient of determination: 0.30987046585364\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220.0</td>\n",
       "      <td>233.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163.0</td>\n",
       "      <td>175.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102.0</td>\n",
       "      <td>127.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170.0</td>\n",
       "      <td>85.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.0</td>\n",
       "      <td>82.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>55.0</td>\n",
       "      <td>135.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>70.0</td>\n",
       "      <td>112.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>191.0</td>\n",
       "      <td>141.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>84.0</td>\n",
       "      <td>159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>25.0</td>\n",
       "      <td>116.320000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test      y_pred\n",
       "0     220.0  233.500000\n",
       "1     163.0  175.200000\n",
       "2     102.0  127.700000\n",
       "3     170.0   85.300000\n",
       "4      59.0   82.200000\n",
       "..      ...         ...\n",
       "141    55.0  135.100000\n",
       "142    70.0  112.766667\n",
       "143   191.0  141.200000\n",
       "144    84.0  159.000000\n",
       "145    25.0  116.320000\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemplo da técnica Random Forest para problemas de regressão:\n",
    "\n",
    "X = load_diabetes().data\n",
    "y = load_diabetes().target\n",
    "\n",
    "df = pd.DataFrame(X, columns=load_diabetes().feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "def rf_regressor(df:pd.DataFrame, \n",
    "                 num_bootstrap_samples:int=3,  # Parâmetro da função que define a quantidade de amostragens para treinamento\n",
    "                 test_size:float=0.25\n",
    "                ) -> pd.DataFrame:\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "    X_test = df_test.drop(['target'], axis=1)\n",
    "    y_test = df_test['target'].rename('y_test')\n",
    "    \n",
    "    # Dicionário para os resultados das predições de cada modelo\n",
    "    y_pred_bagging = {}\n",
    "\n",
    "    for i in range(num_bootstrap_samples):\n",
    "        # Bootstrap\n",
    "        df_train = df_train.sample(n=len(df_train), \n",
    "                                   replace=True)  # Amostragem COM reposição\n",
    "\n",
    "        X_train = df_train.drop(['target'], axis=1)\n",
    "        # Feature selection\n",
    "        X_train = X_train.sample(n=round(X_train.shape[1]/3),  # Cálculo da quantidade de variáveis dividida por 3\n",
    "                                 axis=1)\n",
    "        \n",
    "        y_train = df_train['target']\n",
    "\n",
    "        # Modelagem (base learners)\n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Adicionando os resultados do modelo ao dicionário para agregação das predições\n",
    "        y_pred_bagging.update({i:model.predict(X_test[X_train.columns])})\n",
    "\n",
    "    # Aggregating\n",
    "    y_pred = (pd.DataFrame(y_pred_bagging)\n",
    "                .mean(axis=1)  # Agregando as predições dos modelos baseando n a média dos resultados\n",
    "                .rename('y_pred'))\n",
    " \n",
    "    # Resultados\n",
    "    print(model)\n",
    "    print('Mean squared error:', mean_squared_error(y_true=y_test, \n",
    "                                                   y_pred=y_pred))\n",
    "    print('Coefficient of determination:', r2_score(y_true=y_test, \n",
    "                                                    y_pred=y_pred))\n",
    "    \n",
    "    return pd.concat(objs=[y_test.reset_index(drop=True), \n",
    "                           y_pred], \n",
    "                     axis=1)\n",
    "    \n",
    "rf_regressor(num_bootstrap_samples=10, df=df, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afea5b5-6bed-4c12-adf1-988ce95e0db1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
